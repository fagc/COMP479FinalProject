import pandas as pd
import numpy as np
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.metrics import silhouette_score, silhouette_samples, accuracy_score, f1_score, precision_score, recall_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Load the dataset
data = pd.read_csv("/Users/tpapka/fall2024/comp379/Project/marketing_campaign.csv", sep="\t")

# Drop rows with missing values
data = data.dropna() 

# Feature engineering
data['Age'] = 2024 - data['Year_Birth']  # Getting the age
data['TotalKids'] = data['Kidhome'] + data['Teenhome']  # Total number of children
data['EnrollmentYear'] = pd.to_datetime(data['Dt_Customer'], dayfirst=True).dt.year  # Extracting enrollment year
data['Tenure'] = 2024 - data['EnrollmentYear']  # Tenure

# Dropping unnecessary columns
data = data.drop(['ID', 'Year_Birth', 'Dt_Customer', 'EnrollmentYear'], axis=1)

# Selecting the most relevant features
features = data.drop('Response', axis=1)
target = data['Response']

# One-hot encoding categorical variables
features = pd.get_dummies(features, drop_first=True)

# Split the data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)

# Scaling the features
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

def cluster_and_analyze(x_train, y_train=None, n_clusters=2, random_state=42):
    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init='auto')
    cluster_labels = kmeans.fit_predict(x_train)

    avg_silhouette_score = silhouette_score(x_train, cluster_labels)
    print(f"Average Silhouette Score for k={n_clusters}: {avg_silhouette_score}")

    pca = PCA(n_components=2, random_state=random_state)
    x_train_2d = pca.fit_transform(x_train)

    plt.figure(figsize=(8, 6))
    for cluster in range(n_clusters):
        plt.scatter(x_train_2d[cluster_labels == cluster, 0], 
                    x_train_2d[cluster_labels == cluster, 1], 
                    label=f"Cluster {cluster}", alpha=0.7)
    # plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, c='red', label='Centroids')
    # plt.title(f"PCA Visualization of Clusters (k={n_clusters})")
    # plt.xlabel("PCA Component 1")
    # plt.ylabel("PCA Component 2")
    # plt.legend()
    # plt.show()

    print("\nEvaluation Metrics:")
    print("Accuracy:", accuracy_score(y_train, cluster_labels))
    print("F1 Score:", f1_score(y_train, cluster_labels, average='weighted'))
    print("Precision:", precision_score(y_train, cluster_labels, average='weighted'))
    print("Recall:", recall_score(y_train, cluster_labels, average='weighted'))
    print("\nClassification Report:\n", classification_report(y_train, cluster_labels))

    
    cluster_summary = { # Cluster labels,centers, and Silhouette Score
        'Cluster Labels': cluster_labels,
        'Cluster Centers': kmeans.cluster_centers_,
        'Silhouette Score': avg_silhouette_score
    }

    return kmeans, cluster_summary

kmeans_model, cluster_summary = cluster_and_analyze(x_train, y_train, n_clusters=2)

# print("\nCluster Summary:")
# print(cluster_summary)
